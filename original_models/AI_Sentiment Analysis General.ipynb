{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9b99364-d191-4bdf-8142-bd1e076b491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string \n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0444102-ad36-44e2-92ad-5ad7a8a26c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca0a642-4671-42f1-b1b6-6832a3d84eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf5baaba-e8c3-4701-ad43-fc91c0023a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading and cleaning text\n",
    "text= open(\"SE/sampleText.txt\",encoding=\"utf-8\").read()\n",
    "lower_case = text.lower()\n",
    "cleaned_text = lower_case.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "091398dd-d875-43de-ba76-daff25c2ed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic NLKT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62abdbd0-5f2a-4444-914a-a91dab16a77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ask',\n",
       " 'sityush',\n",
       " 'to',\n",
       " 'clean',\n",
       " 'up',\n",
       " 'his',\n",
       " 'behavior',\n",
       " 'than',\n",
       " 'issue',\n",
       " 'me']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(cleaned_text)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbcdfa4d-ad02-4541-8a29-cdaf9610117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Stop Words\n",
    "final_words = []\n",
    "for word in tokens:\n",
    "    if word not in stopwords.words('english'):\n",
    "        final_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c06ae12e-ee43-43e8-9711-1f4aea286aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization - From plural to single + Base form of a word (example better-> good)\n",
    "lemma_words = []\n",
    "for word in final_words:\n",
    "    word = WordNetLemmatizer().lemmatize(word)\n",
    "    lemma_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90e6a299-462c-4c5d-8fec-863460effbd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ask', 'VB'),\n",
       " ('sityush', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('clean', 'VB'),\n",
       " ('up', 'RP'),\n",
       " ('his', 'PRP$'),\n",
       " ('behavior', 'NN'),\n",
       " ('than', 'IN'),\n",
       " ('issue', 'VB'),\n",
       " ('me', 'PRP')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(tokens)\n",
    "tagged[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e947928f-3259-40ea-94c6-b68d80e056ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VADER Seniment Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "151d8b24-e98f-426e-83a3-127ae6724197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d9dca3d-3968-40ab-be48-beab21329b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.238, 'neu': 0.495, 'pos': 0.267, 'compound': 0.0772}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#EXPERIMENT\n",
    "exp=' '.join(lemma_words)\n",
    "sia.polarity_scores(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ca2e45e-6179-4efb-8f02-2bca4b65dbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.222, 'neu': 0.505, 'pos': 0.273, 'compound': 0.128}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp=' '.join(final_words)\n",
    "sia.polarity_scores(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45125205-d63f-47a1-a2ea-b45a0a84e105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.148, 'neu': 0.671, 'pos': 0.181, 'compound': 0.128}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46c21257-8a05-4e95-a483-6793c7465784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Roberta Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d97cd147-dfd4-4f5c-a83a-77d38626d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2335e1b9-060e-4914-81db-0eae2e1cac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8828f29c-a711-4e9c-8fc1-80aa95bbe67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roberta_neg': 0.76321274, 'roberta_neu': 0.2285487, 'roberta_pos': 0.008238544}\n"
     ]
    }
   ],
   "source": [
    "# Run for Roberta Model\n",
    "encoded_text = tokenizer(cleaned_text, return_tensors='pt')\n",
    "output = model(**encoded_text)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "scores_dict = {\n",
    "    'roberta_neg' : scores[0],\n",
    "    'roberta_neu' : scores[1],\n",
    "    'roberta_pos' : scores[2]\n",
    "}\n",
    "print(scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89729927-0aca-4f87-be00-3647c4512b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline to check accuracy\n",
    "# Load your labeled dataset\n",
    "data = pd.DataFrame({\n",
    "    \"text\":[\"This is good day\", \"guess that depends on if you want to be on the jury\", \"I am not feeling good.\"],\n",
    "    \"label\":[\"positive\", \"neutral\", \"negative\"]\n",
    "})\n",
    "# Map labels to indices\n",
    "label_map = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "\n",
    "# Predict and evaluate\n",
    "correct_predictions = 0\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    text = row[\"text\"]\n",
    "    true_label = label_map[row[\"label\"]]\n",
    "    \n",
    "    # Tokenize and predict\n",
    "    encoded_text = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = softmax(output[0][0].detach().numpy())\n",
    "    predicted_label = scores.argmax()  # Get the index of the max score\n",
    "    \n",
    "    # Compare with true label\n",
    "    if predicted_label == true_label:\n",
    "        correct_predictions += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d841af13-0f0e-4b56-9ec3-b5db29fab3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / len(data)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
